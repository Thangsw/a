const { GoogleGenerativeAI } = require('@google/generative-ai');
const keyManager = require('./keyManager');
const db = require('./database');
const { log } = require('./colors');
const { parseAIJSON } = require('./json_helper');
const nicheManager = require('./nicheManager');

/**
 * SHU Step 3: Module Planning Engine
 */

async function planModules(projectId, analyzedData, feedback = null, niche = 'dark_psychology_de', targetWords = null) {
    const nicheProfile = nicheManager.getProfile(niche);

    // Auto-detect targetWords if missing
    if (!targetWords) {
        targetWords = nicheProfile.pipeline_settings?.target_words_per_block || 1500;
        if (niche === 'dark_psychology_de') targetWords = 4500; // Total for 3 units
    }

    log.info(`üß† [SHU B∆∞·ªõc 3] ƒêang l·∫≠p k·∫ø ho·∫°ch module cho D·ª± √°n: ${projectId} (Ng√°ch: ${niche}, M·ª•c ti√™u: ${targetWords} t·ª´)${feedback ? " (ƒêang tinh ch·ªânh d·ª±a tr√™n ph·∫£n h·ªìi)" : ""}`);

    const validRoles = nicheManager.getRoles(niche);

    const prompt = `
You are a senior YouTube editor specializing in ${nicheProfile.writer_role}.

TASK:
${feedback ? `REFINE the following module plan based on the provided feedback to improve narrative flow, tension building, and keyword placement.

RULES FOR REFINEMENT:
- Do NOT change the total number of modules.
- Do NOT remove HOOK or OPEN_END.
- Improve narrative flow and escalation.
- Adjust goals to be sharper and more focused.
- Ensure only the requested roles are used.
- You MUST preserve the original role order defined by the niche role map.

FEEDBACK TO FIX:
${JSON.stringify(feedback)}

CURRENT PLAN TO REFINE (Base Plan):
${JSON.stringify(feedback?.module_plan || analyzedData.module_plan)}` : `Plan the optimal module structure for a long-form YouTube ${niche} video.`}

CONSTRUCTED CONTEXT:
- Niche: ${niche}
- Tone Strategy: ${Array.isArray(nicheProfile.tone) ? nicheProfile.tone.join(", ") : nicheProfile.tone}
- Dominant emotion: ${analyzedData.dominant_trigger}
- Hook strength score: ${analyzedData.hook_score}
- Core Keyword: ${analyzedData.core_keyword || "N/A"}

RULES:
- Total modules must be between 8 and 10
- Each module must have a clear narrative role
- Structure must escalate tension gradually (Single-Peak approach)
- IMPORTANT: You MUST choose exactly ONE role from the peak role list (PEAK, REALIZATION, TURNING_POINT, SHIFT, COLD_RESOLUTION) to serve as the narrative climax. Do NOT use more than one peak role in your plan.
- Final module must leave an open loop (no conclusion)

AVAILABLE MODULE ROLES:
${validRoles.join("\n")}

OUTPUT FORMAT (JSON ONLY):
[
  {
    "index": 1,
    "role": "HOOK",
    "goal": "..."
  }
]
`;

    let attempts = 0;
    while (attempts < 3) {
        attempts++;
        try {
            const aiPlan = await executeAIPlanner(projectId, prompt);

            if (!Array.isArray(aiPlan)) {
                throw new Error("AI failed to return a valid module list.");
            }

            // B3.3: Tool Enrichment (Rule-based)
            const enrichedModules = aiPlan.map(module => {
                if (!validRoles.includes(module.role)) {
                    throw new Error(`Invalid module role from AI: ${module.role}`);
                }

                let word_target = 500;
                let allowed_keyword_type = ["support"];

                const roleProps = nicheManager.getRoleProperty(module.role);
                const wordBias = roleProps.word_bias || 0;

                if (nicheProfile.keyword_discipline === "loose") {
                    allowed_keyword_type = [];
                }

                const scaleFactor = targetWords / 5000;

                switch (module.role) {
                    case "HOOK":
                        word_target = Math.round((120 + wordBias) * Math.max(0.8, scaleFactor));
                        if (nicheProfile.keyword_discipline !== "loose") allowed_keyword_type = ["core", "ctr"];
                        break;
                    case "PEAK":
                    case "REALIZATION":
                    case "TURNING_POINT":
                    case "SHIFT":
                    case "COLD_RESOLUTION":
                        word_target = Math.round((650 + wordBias) * (targetWords / 5000));
                        if (analyzedData.hook_score < 7) {
                            word_target = Math.round((500 + wordBias) * (targetWords / 5000));
                        }
                        if (nicheProfile.keyword_discipline !== "loose") allowed_keyword_type = ["core", "support"];
                        break;
                    case "OPEN_END":
                    case "OPEN_LOOP":
                        word_target = Math.round((300 + wordBias) * (targetWords / 5000));
                        if (nicheProfile.keyword_discipline !== "loose") allowed_keyword_type = ["core"];
                        break;
                    default:
                        word_target = Math.round((550 + wordBias) * (targetWords / 5000));
                        break;
                }

                return {
                    ...module,
                    word_target,
                    allowed_keyword_type
                };
            });

            validateModulePlan(enrichedModules);

            const totalWords = enrichedModules.reduce((sum, m) => sum + m.word_target, 0);

            await db.saveModulePlan(projectId, {
                modules: enrichedModules,
                version: "v1.0",
                hook_score: analyzedData.hook_score,
                total_word_estimate: totalWords
            });

            const finalResult = {
                module_plan: enrichedModules,
                total_word_estimate: totalWords,
                status: "ready_for_module_generation"
            };

            log.success(`‚úÖ B∆∞·ªõc 3 Ho√†n t·∫•t: ƒê√£ l·∫≠p k·∫ø ho·∫°ch cho ${enrichedModules.length} modules (L∆∞·ª£t th·ª≠: ${attempts}).`);
            return finalResult;

        } catch (err) {
            log.warn(`‚ö†Ô∏è B∆∞·ªõc 3 - L∆∞·ª£t th·ª≠ ${attempts} th·∫•t b·∫°i: ${err.message}`);
            if (attempts === 3) throw err;
            await new Promise(r => setTimeout(r, 1000));
        }
    }
}

function validateModulePlan(modules) {
    if (modules.length < 8 || modules.length > 10) {
        throw new Error(`S·ªë l∆∞·ª£ng module kh√¥ng h·ª£p l·ªá: ${modules.length}. Ph·∫£i t·ª´ 8-10.`);
    }

    modules.forEach((m, i) => {
        if (m.index !== i + 1) {
            throw new Error(`Index module kh√¥ng li√™n t·ª•c t·∫°i v·ªã tr√≠ ${i} (K·ª≥ v·ªçng ${i + 1}, nh·∫≠n ƒë∆∞·ª£c ${m.index})`);
        }
    });

    const roles = modules.map(m => m.role);

    if (modules[0].role !== "HOOK") {
        throw new Error("Module ƒë·∫ßu ti√™n ph·∫£i l√† HOOK");
    }

    const peakRoles = ["PEAK", "REALIZATION", "TURNING_POINT", "SHIFT", "COLD_RESOLUTION"];
    const foundPeak = roles.filter(r => peakRoles.includes(r));
    if (foundPeak.length !== 1) {
        throw new Error(`S·ªë l∆∞·ª£ng PEAK kh√¥ng h·ª£p l·ªá: ${foundPeak.length} (${foundPeak.join(", ")}). Ph·∫£i c√≥ ƒë√∫ng 1 peak role (${peakRoles.join(", ")}).`);
    }

    if (!roles.includes("HOOK") && !roles.includes("HOOK_THREAT")) throw new Error("Thi·∫øu module HOOK");

    const lastModule = modules[modules.length - 1];
    if (lastModule.role !== "OPEN_END" && lastModule.role !== "OPEN_LOOP") {
        throw new Error(`Module cu·ªëi c√πng ph·∫£i l√† OPEN_END ho·∫∑c OPEN_LOOP, nh∆∞ng nh·∫≠n ƒë∆∞·ª£c ${lastModule.role}`);
    }

    const totalWords = modules.reduce((sum, m) => sum + m.word_target, 0);
    log.info(`üìä T·ªïng d·ª± l∆∞·ª£ng b√†i vi·∫øt d·ª± ki·∫øn: ${totalWords} t·ª´.`);
}

async function executeAIPlanner(projectId, prompt) {
    const MODEL_PRIORITY = ['gemini-3-flash-preview', 'gemma-3-27b-it'];
    let lastError = null;

    for (const modelName of MODEL_PRIORITY) {
        try {
            return await keyManager.executeWithRetry(async (apiKey) => {
                const genAI = new GoogleGenerativeAI(apiKey);
                log.info(`ü§ñ ƒêang l·∫≠p k·∫ø ho·∫°ch [Model: ${modelName}] b·∫±ng m·ªôt API Key kh·∫£ d·ª•ng...`);
                const model = genAI.getGenerativeModel({
                    model: modelName,
                    apiVersion: 'v1beta',
                    generationConfig: { maxOutputTokens: 8192, temperature: 0.7 }
                });

                const result = await model.generateContent(prompt);
                const response = await result.response;
                const text = response.text();
                const json = parseAIJSON(text, "Planner");

                if (json) {
                    if (projectId) {
                        const tokens = response.usageMetadata ? response.usageMetadata.totalTokenCount : 0;
                        await db.logAIAction(projectId, 'PLANNER_GEN', modelName, tokens, text);
                    }
                    return json;
                }
                throw new Error("Ph·∫£n h·ªìi AI kh√¥ng h·ª£p l·ªá");
            });
        } catch (err) {
            lastError = err;
            const errMsg = err.message.toLowerCase();
            if (errMsg.includes('429') || errMsg.includes('quota') || errMsg.includes('503') || errMsg.includes('overloaded') || errMsg.includes('exhausted')) {
                log.warn(`‚ö†Ô∏è Model ${modelName} th·∫•t b·∫°i tr√™n T·∫§T C·∫¢ c√°c Keys. ƒêang th·ª≠ model ti·∫øp theo...`);
                continue;
            }
            throw err;
        }
    }
    throw lastError;
}

module.exports = { planModules };
